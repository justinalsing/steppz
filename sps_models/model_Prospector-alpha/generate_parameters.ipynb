{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "233d0444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justinalsing/.pyenv/versions/3.8.6/envs/base3.8/lib/python3.8/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from scipy.integrate import cumtrapz\n",
    "from scipy.stats import gaussian_kde\n",
    "import scipy.stats as stats\n",
    "from getdist import plots, MCSamples\n",
    "import matplotlib as mpl\n",
    "from astropy.cosmology import Planck15\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "import fsps\n",
    "import emcee\n",
    "from scipy.special import hyp2f1\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tqdm\n",
    "from tqdm import trange\n",
    "tfb = tfp.bijectors\n",
    "tfd = tfp.distributions\n",
    "tfkl = tf.keras.layers\n",
    "tfpl = tfp.layers\n",
    "tfk = tf.keras\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/justinalsing/Documents/science/steppz/code')\n",
    "from plotting import triangle_plot\n",
    "from utils import *\n",
    "from priors import *\n",
    "from affine import *\n",
    "from ndes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf0dab",
   "metadata": {},
   "source": [
    "Import relevant models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb0fa14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the relevant models\n",
    "log10sSFR_emulator = RegressionNetwork(restore=True, restore_filename='ProspectorAlpha_log10sSFR_emulator.pkl')\n",
    "baseline_SFR_prior_log_prob = RegressionNetwork(restore=True, restore_filename='ProspectorAlpha_baseline_SFR_prior_logprob.pkl')\n",
    "\n",
    "# set up the prior class\n",
    "Prior = ProspectorAlphaBaselinePrior(baselineSFRprior=baseline_SFR_prior_log_prob, \n",
    "                             log10sSFRemulator=log10sSFR_emulator, \n",
    "                             log10sSFRprior=log10sSFRpriorMizuki, \n",
    "                             log10sSFRuniformlimits=tfd.Uniform(low=-14, high=-8), \n",
    "                             redshift_prior=redshift_volume_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f12b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function anchor_points_to_coefficients at 0x1528660d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function anchor_points_to_coefficients at 0x1528660d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function RegressionNetwork.__call__ at 0x1529ebd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# initialize walkers for sampling\n",
    "n_walkers = 2000\n",
    "n_steps = 1000\n",
    "\n",
    "# baseline prior draws\n",
    "bijector = tfb.Blockwise([tfb.Invert(tfb.Chain([tfb.Invert(tfb.NormalCDF()), tfb.Scale(1./(Prior.upper[_]-Prior.lower[_])), tfb.Shift(-Prior.lower[_])])) for _ in range(Prior.n_sps_parameters)])\n",
    "baseline_draws = bijector(Prior.baselinePrior.sample((30000, Prior.n_sps_parameters)))\n",
    "\n",
    "# reject those outside SFR prior range\n",
    "sfh = tf.gather(baseline_draws, [2, 3, 4, 5, 6, 7, 1, 14], axis=-1)\n",
    "log10sSFR = tf.squeeze(log10sSFR_emulator(sfh))\n",
    "baseline_draws = tf.squeeze(tf.gather(baseline_draws, indices=tf.where((log10sSFR > -14) & (log10sSFR < -8)), axis=0), axis=1)\n",
    "\n",
    "# convert log10M to N\n",
    "baseline_draws = baseline_draws.numpy()\n",
    "baseline_draws[...,0] = -2.5*baseline_draws[...,0] + distance_modulus(tf.math.maximum(1e-5, baseline_draws[...,-1]))\n",
    "log_prior = Prior.log_prob(baseline_draws).numpy()\n",
    "baseline_draws = baseline_draws[~np.isinf(log_prior),:]\n",
    "baseline_draws = tf.convert_to_tensor(baseline_draws)\n",
    "\n",
    "# current state\n",
    "current_state = [baseline_draws[0:n_walkers,:], baseline_draws[n_walkers:2*n_walkers,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cb3b2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function RegressionNetwork.__call__ at 0x1529ad280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function RegressionNetwork.__call__ at 0x1529ebd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [02:49<00:00,  5.91it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.92it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.92it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.88it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.91it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.93it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.88it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.86it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.91it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.87it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.88it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.94it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.94it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.89it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.95it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.93it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.92it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.90it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.91it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.91it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.87it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.91it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.93it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.95it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.89it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.92it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.87it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.85it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.91it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.92it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.90it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.80it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.91it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.92it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.88it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.91it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.89it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.86it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.90it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.90it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.89it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.86it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.84it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.89it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.87it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.87it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.85it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.87it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.86it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.82it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.90it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.87it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.90it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.86it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.87it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.85it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.84it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.90it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.89it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.86it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.87it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.90it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.88it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.81it/s]\n",
      "100%|██████████| 24/24 [00:04<00:00,  5.80it/s]\n"
     ]
    }
   ],
   "source": [
    "n_batches = 64\n",
    "n_samples = 100000\n",
    "\n",
    "# burn in\n",
    "chain = affine_sample(Prior.log_prob, 1000, current_state)\n",
    "current_state = [chain[-1,0:n_walkers,:], chain[-1,n_walkers:,:]]\n",
    "\n",
    "for batch in range(n_batches):\n",
    "\n",
    "    chain = affine_sample(Prior.log_prob, 25, current_state)\n",
    "    current_state = [chain[-1,0:n_walkers,:], chain[-1,n_walkers:,:]]\n",
    "    parameters = Prior.bijector(chain).numpy().reshape((25*2*n_walkers, 15))\n",
    "    \n",
    "    # save the parameters\n",
    "    np.save('../model_Prospector-alpha/training_data_prior/parameters/parameters{}.npy'.format(batch), parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc300dce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
