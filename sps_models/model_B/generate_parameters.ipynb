{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f878de66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justinalsing/.pyenv/versions/3.8.6/envs/base3.8/lib/python3.8/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from scipy.integrate import cumtrapz\n",
    "from scipy.stats import gaussian_kde\n",
    "import scipy.stats as stats\n",
    "from getdist import plots, MCSamples\n",
    "import matplotlib as mpl\n",
    "from astropy.cosmology import Planck15\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "import fsps\n",
    "import emcee\n",
    "from scipy.special import hyp2f1\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tqdm\n",
    "from tqdm import trange\n",
    "tfb = tfp.bijectors\n",
    "tfd = tfp.distributions\n",
    "tfkl = tf.keras.layers\n",
    "tfpl = tfp.layers\n",
    "tfk = tf.keras\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/justinalsing/Documents/science/steppz/code')\n",
    "from plotting import triangle_plot\n",
    "from utils import *\n",
    "from priors import *\n",
    "from affine import *\n",
    "from ndes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9588396",
   "metadata": {},
   "source": [
    "Import relevant models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61321d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the relevant models\n",
    "log10sSFR_emulator = RegressionNetwork(restore=True, restore_filename='DPL_log10sSFR_emulator.pkl')\n",
    "baseline_SFR_prior_log_prob = RegressionNetwork(restore=True, restore_filename='DPL_baseline_SFR_prior_logprob.pkl')\n",
    "\n",
    "# set up the prior class\n",
    "Prior = ModelABBaselinePrior(baselineSFRprior=baseline_SFR_prior_log_prob, \n",
    "                             log10sSFRemulator=log10sSFR_emulator, \n",
    "                             log10sSFRuniformlimits=tfd.Uniform(low=-14, high=-7),\n",
    "                             FMRprior='curti',\n",
    "                             SFSprior='leja',\n",
    "                             MFprior=None,\n",
    "                             redshift_prior=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e899457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function log10SFRpriorJoel at 0x137e66e50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function log10SFRpriorJoel at 0x137e66e50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# initialize walkers for sampling\n",
    "n_walkers = 2000\n",
    "n_steps = 1000\n",
    "\n",
    "# baseline prior draws\n",
    "bijector = tfb.Blockwise([tfb.Invert(tfb.Chain([tfb.Invert(tfb.NormalCDF()), tfb.Scale(1./(Prior.upper[_]-Prior.lower[_])), tfb.Shift(-Prior.lower[_])])) for _ in range(Prior.n_sps_parameters)])\n",
    "baseline_draws = bijector(Prior.baselinePrior.sample((30000, Prior.n_sps_parameters)))\n",
    "\n",
    "# reject those outside SFR prior range\n",
    "sfh = baseline_draws[...,-4:]\n",
    "log10sSFR = tf.squeeze(log10sSFR_emulator(sfh))\n",
    "baseline_draws = tf.squeeze(tf.gather(baseline_draws, indices=tf.where((log10sSFR > -14) & (log10sSFR < -7)), axis=0), axis=1)\n",
    "\n",
    "# convert log10M to N\n",
    "baseline_draws = baseline_draws.numpy()\n",
    "baseline_draws[...,0] = -2.5*baseline_draws[...,0] + distance_modulus(tf.math.maximum(1e-5, baseline_draws[...,-1]))\n",
    "log_prior = Prior.log_prob(baseline_draws).numpy()\n",
    "baseline_draws = baseline_draws[~np.isinf(log_prior),:]\n",
    "baseline_draws = tf.convert_to_tensor(baseline_draws)\n",
    "\n",
    "# current state\n",
    "current_state = [baseline_draws[0:n_walkers,:], baseline_draws[n_walkers:2*n_walkers,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65f949ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4999/4999 [09:01<00:00,  9.24it/s]\n"
     ]
    }
   ],
   "source": [
    "chain = affine_sample(Prior.log_prob, 5000, current_state)\n",
    "current_state = [chain[-1,0:n_walkers,:], chain[-1,n_walkers:,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb0b2f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = Prior.bijector(chain[-1,...]).numpy()\n",
    "log10M = (theta[:,0] - distance_modulus(theta[:,-1]).numpy()) / (-2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d34dfac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.156786,  9.231619, 11.903885, ...,  8.751119, 12.917892,\n",
       "       10.596551], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f71162c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:02<00:00,  9.20it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.34it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.37it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.34it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.38it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.35it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.35it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.37it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.33it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.37it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.29it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.38it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.35it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.36it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.35it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.35it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.37it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.25it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.28it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.21it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.30it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.28it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.30it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.21it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.05it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.12it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.12it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.23it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.24it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.18it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.25it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.25it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.25it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.11it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.24it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.28it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.26it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.15it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.21it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.20it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.20it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.15it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.20it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.23it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.21it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.19it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.22it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.24it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.26it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.17it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.22it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.14it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.08it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.10it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.17it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.15it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.14it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.19it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.09it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.19it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.16it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  8.95it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.14it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.19it/s]\n"
     ]
    }
   ],
   "source": [
    "n_batches = 64\n",
    "n_samples = 100000\n",
    "\n",
    "# burn in\n",
    "#chain = affine_sample(Prior.log_prob, 5000, current_state)\n",
    "#current_state = [chain[-1,0:n_walkers,:], chain[-1,n_walkers:,:]]\n",
    "\n",
    "for batch in range(n_batches):\n",
    "\n",
    "    chain = affine_sample(Prior.log_prob, 25, current_state)\n",
    "    current_state = [chain[-1,0:n_walkers,:], chain[-1,n_walkers:,:]]\n",
    "    parameters = Prior.bijector(chain).numpy().reshape((25*2*n_walkers, 9))\n",
    "    \n",
    "    # save the parameters\n",
    "    np.save('../model_B/training_data/parameters/parameters{}.npy'.format(batch), parameters)\n",
    "    np.save('../model_A/training_data/parameters/parameters{}.npy'.format(batch), parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b619e2",
   "metadata": {},
   "source": [
    "Generate data from the prior (including volume redshift term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0a69162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the prior class\n",
    "Prior = ModelABBaselinePrior(baselineSFRprior=baseline_SFR_prior_log_prob, \n",
    "                             log10sSFRemulator=log10sSFR_emulator, \n",
    "                             log10sSFRprior=log10sSFRpriorMizuki, \n",
    "                             log10sSFRuniformlimits=tfd.Uniform(low=-14, high=-7), \n",
    "                             redshift_prior=redshift_volume_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8dc7c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [01:41<00:00,  9.80it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.77it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.57it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.81it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.83it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.79it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.83it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.83it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.67it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.83it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.78it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.86it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.86it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.78it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.77it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.86it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.86it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.86it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.86it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.83it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.43it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.77it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.41it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.64it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.84it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.80it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.78it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.85it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.83it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.86it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.83it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.88it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.86it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.88it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.78it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.77it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.83it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.83it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.83it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.75it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.75it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.84it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.85it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.80it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.71it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.67it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.65it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.62it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.52it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.69it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.84it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.70it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.78it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.76it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.73it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.82it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.76it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.79it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.66it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.74it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.55it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.82it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.80it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.76it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00,  9.77it/s]\n"
     ]
    }
   ],
   "source": [
    "n_batches = 64\n",
    "n_samples = 100000\n",
    "\n",
    "# burn in\n",
    "chain = affine_sample(Prior.log_prob, 1000, current_state)\n",
    "current_state = [chain[-1,0:n_walkers,:], chain[-1,n_walkers:,:]]\n",
    "\n",
    "for batch in range(n_batches):\n",
    "\n",
    "    chain = affine_sample(Prior.log_prob, 25, current_state)\n",
    "    current_state = [chain[-1,0:n_walkers,:], chain[-1,n_walkers:,:]]\n",
    "    parameters = Prior.bijector(chain).numpy().reshape((25*2*n_walkers, 9))\n",
    "    \n",
    "    # save the parameters\n",
    "    np.save('../model_B/training_data_prior/parameters/parameters{}.npy'.format(batch), parameters)\n",
    "    np.save('../model_A/training_data_prior/parameters/parameters{}.npy'.format(batch), parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
